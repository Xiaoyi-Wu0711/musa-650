{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## HW4 - EuroSAT Land Use and Land Cover Classification using Deep Learning\n",
    " \n",
    "In this homework your task is to implement deep learning models to solve a typical problem in satellite imaging  using a benchmark dataset. The homework was designed to make you work on increasingly more complex models. We hope that the homework will be very helpful to improve your skills and knowledge in deep learning!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1:\n",
    "\n",
    "- Visit the EuroSAT data description page and download the data: https://github.com/phelber/eurosat\n",
    "\n",
    "- Split the data into training (50%) and testing sets (50%), stratified on class labels (equal percentage of each class type in train and test sets).\n",
    "\n",
    "- Convert each RGB image to grayscale and flatten the images into a data matrix (n x p: n = #samples, p = #pixels in each image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten,Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY = r'EuroSAT\\2750'\n",
    "\n",
    "CATEGORIES = ['SeaLake', 'River','Residential','PermanentCrop',\n",
    "              'Pasture','Industrial','Highway','HerbaceousVegetation',\n",
    "             'Forest','AnnualCrop']\n",
    "num_class=(len(CATEGORIES))\n",
    "image=PIL.Image.open('EuroSAT/2750/Forest/Forest_1.jpg',mode='r', formats=None)\n",
    "pix=image.load()\n",
    "print(image.size)\n",
    "w=image.size[0]\n",
    "h=image.size[1]\n",
    "n_spectrum = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1= []\n",
    "X_1=[]\n",
    "Y_1=[]\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        new_arr = cv2.resize(arr, (64, 64))\n",
    "        X_1.append(new_arr)\n",
    "        Y_1.append(label)\n",
    "        data_1.append([new_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_value_1=np.array(X_1)\n",
    "X_value_1=X_value_1.reshape(X_value_1.shape[0],-1)\n",
    "X_value_1=X_value_1.astype('float32')\n",
    "X_value_1/=255\n",
    "Y_value_1=np.array(Y_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(X_value_1, Y_value_1, stratify = Y_value_1, train_size = 0.5, random_state=42)\n",
    "y_train_1 = to_categorical(y_train_1, num_class)\n",
    "y_test_1 = to_categorical(y_test_1, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 4096)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size=(x_train_1.shape)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2:\n",
    "\n",
    "- Implement a first deep learning model (M.1) using a fully connected network with a single fully connected layer (i.e: input layer + fully connected layer as the output layer). \n",
    "\n",
    "###  CNN:\n",
    "1. reduce para: kernel sharing para, proximity in pixel, kernel is learned by the DNN\n",
    "\n",
    "Q2.1: Calculate classification accuracy on the test data. \n",
    "0.17444443702697754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,970\n",
      "Trainable params: 40,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(num_class, activation='softmax', input_shape=(batch_size[1],)))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_1.fit(x_train_1, y_train_1,\n",
    "                    batch_size=64,\n",
    "                      # unbiased sampling, but large the size the lower variance\n",
    "                      # 32->64\n",
    "                    epochs=50,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test_1, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.196153163909912\n",
      "Test accuracy: 0.263481467962265\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_test_1, y_test_1, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3:\n",
    "\n",
    "- Implement a second deep learning model (M.2) adding an additional fully connected hidden layer (with an arbitrary number of nodes) to the previous model. \n",
    "\n",
    "\n",
    "Q3.1: Calculate classification accuracy on the test data. \n",
    "0.29822221398353577 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,102,794\n",
      "Trainable params: 2,102,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(512, activation='relu', input_shape=(batch_size[1],)))\n",
    "model_2.add(Dense(num_class, activation='softmax'))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_2.fit(x_train_1, y_train_1,\n",
    "                    batch_size=64,\n",
    "                      # unbiased sampling, but large the size the lower variance\n",
    "                      # 32->64\n",
    "                    epochs=50,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test_1, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.7196553945541382\n",
      "Test accuracy: 0.3468148112297058\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate(x_test_1, y_test_1, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4:\n",
    "\n",
    "- Implement a third deep learning model (M.3) adding two additional fully connected hidden layers (with arbitrary number of nodes) for a total of four, as well as drop-out layers to the previous model. \n",
    "\n",
    "#todo: how many layers in total\n",
    "\n",
    "Q4.1: Calculate classification accuracy on the test data.\n",
    "\n",
    "Q4.2: Compare against previous models. Which model was the \"best\"? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 216)               110808    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                13888     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,223,010\n",
      "Trainable params: 2,223,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# softmax: multi-class prob\n",
    "# relu: positive value \n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(512, activation='relu', input_shape=(batch_size[1],)))\n",
    "model_3.add(Dense(216, activation='relu'))\n",
    "model_3.add(Dense(64, activation='relu'))\n",
    "model_3.add(Dropout(0.25))\n",
    "model_3.add(Dense(num_class, activation='softmax'))\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_3.fit(x_train_1, y_train_1,\n",
    "                    batch_size=64,\n",
    "\n",
    "                    epochs=50,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test_1, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.2947914600372314\n",
      "Test accuracy: 0.1111111119389534\n"
     ]
    }
   ],
   "source": [
    "score = model_3.evaluate(x_test_1, y_test_1, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5:\n",
    "\n",
    "- Take the original RGB images and do not vectorize them. Use these images as the data input for the following models (M.4 and M.5).\n",
    "- Implement a fourth CNN model (M.4) that includes the following layers: Conv2D, MaxPooling2D, Dropout, Flatten, Dense. \n",
    "\n",
    "Q5.1: Calculate classification accuracy on the test data.\n",
    "\n",
    "Q5.2: Compare against previous models. Which model was the \"best\"? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "X=[]\n",
    "Y=[]\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        new_arr = cv2.resize(arr, (64, 64))\n",
    "        X.append(new_arr)\n",
    "        Y.append(label)\n",
    "        data.append([new_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 64, 64, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_value=X.astype('float32')\n",
    "X_value/=255\n",
    "Y_value=np.array(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_value, Y_value, stratify = Y_value, train_size = 0.5, random_state=42)\n",
    "y_train = to_categorical(y_train, num_class)\n",
    "y_test = to_categorical(y_test, num_class)\n",
    "\n",
    "input_shape=(64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                307530    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308,426\n",
      "Trainable params: 308,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',input_shape=input_shape\n",
    "                ))\n",
    "\n",
    "model_4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(num_class, activation='softmax'))\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 33s 149ms/step - loss: 1.6715 - accuracy: 0.3901 - val_loss: 1.3090 - val_accuracy: 0.4890\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 28s 134ms/step - loss: 1.2586 - accuracy: 0.5361 - val_loss: 1.1920 - val_accuracy: 0.5866\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 29s 138ms/step - loss: 1.1159 - accuracy: 0.6007 - val_loss: 1.1511 - val_accuracy: 0.5787\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 29s 139ms/step - loss: 1.0219 - accuracy: 0.6423 - val_loss: 0.9549 - val_accuracy: 0.6709\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 30s 141ms/step - loss: 0.9459 - accuracy: 0.6663 - val_loss: 0.9584 - val_accuracy: 0.6652\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 31s 145ms/step - loss: 0.8932 - accuracy: 0.6935 - val_loss: 0.9256 - val_accuracy: 0.6913\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 32s 153ms/step - loss: 0.8501 - accuracy: 0.7071 - val_loss: 0.9755 - val_accuracy: 0.6804\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 34s 159ms/step - loss: 0.8000 - accuracy: 0.7248 - val_loss: 1.0462 - val_accuracy: 0.6454\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 31s 145ms/step - loss: 0.7638 - accuracy: 0.7395 - val_loss: 0.9548 - val_accuracy: 0.6363\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 30s 143ms/step - loss: 0.7329 - accuracy: 0.7520 - val_loss: 1.4873 - val_accuracy: 0.5317\n",
      "Test loss: 1.487349510192871\n",
      "Test accuracy: 0.5317037105560303\n"
     ]
    }
   ],
   "source": [
    "history = model_4.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6:\n",
    "\n",
    "- Using RGB images from S5, implement a fifth deep learning model (M.5) targeting accuracy that will outperform all previous models. You are free to use any tools and techniques, as well as pre-trained models for transfer learning. \n",
    "\n",
    "Q6.1: Describe the model you built, and why you chose it.\n",
    "\n",
    "Q6.2: Calculate classification accuracy on the test data.\n",
    "\n",
    "Q6.3: Compare against previous models. Which model was the \"best\"? Why?\n",
    "\n",
    "Q6.4: What are the two classes with the highest labeling error? Explain using data and showing mis-classified examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                92170     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,490\n",
      "Trainable params: 148,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(Dropout(0.25))\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(num_class, activation='softmax'))\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 60s 279ms/step - loss: 1.6790 - accuracy: 0.3624 - val_loss: 1.2301 - val_accuracy: 0.5621\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 58s 274ms/step - loss: 1.2057 - accuracy: 0.5617 - val_loss: 1.0119 - val_accuracy: 0.6242\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 58s 276ms/step - loss: 1.0082 - accuracy: 0.6439 - val_loss: 1.5864 - val_accuracy: 0.4594\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 58s 276ms/step - loss: 0.8837 - accuracy: 0.6870 - val_loss: 0.9666 - val_accuracy: 0.6301\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 58s 276ms/step - loss: 0.7902 - accuracy: 0.7167 - val_loss: 0.6758 - val_accuracy: 0.7599\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 59s 278ms/step - loss: 0.7176 - accuracy: 0.7430 - val_loss: 0.8177 - val_accuracy: 0.6840\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 58s 276ms/step - loss: 0.6902 - accuracy: 0.7559 - val_loss: 0.6874 - val_accuracy: 0.7441\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 61s 288ms/step - loss: 0.6241 - accuracy: 0.7771 - val_loss: 0.6244 - val_accuracy: 0.7759\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.5898 - accuracy: 0.7954 - val_loss: 0.6754 - val_accuracy: 0.7536\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 59s 280ms/step - loss: 0.5335 - accuracy: 0.8136 - val_loss: 0.7333 - val_accuracy: 0.7343\n",
      "Test loss: 0.7332733869552612\n",
      "Test accuracy: 0.7342963218688965\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model_5.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model_5.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7:\n",
    "\n",
    "- Apply your best model on multispectral images. You may use whichever image channels you wish, so long as you use more than just RGB (although you are not required to use any color channels).\n",
    "\n",
    "Q7.1: Calculate classification accuracy on the test data.\n",
    "\n",
    "Q7.2: Compare against results using RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'EuroSATallBands\\ds\\images\\remote_sensing\\otherDatasets\\sentinel_2\\tif'\n",
    "\n",
    "CATEGORIES = ['SeaLake', 'River','Residential','PermanentCrop',\n",
    "              'Pasture','Industrial','Highway','HerbaceousVegetation',\n",
    "             'Forest','AnnualCrop']\n",
    "num_class=(len(CATEGORIES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "data_2= []\n",
    "X_2=[]\n",
    "Y_2=[]\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = tifffile.imread(img_path)\n",
    "#         new_arr = cv2.resize(arr, (64, 64))\n",
    "        X_2.append(arr)\n",
    "        Y_2.append(label)\n",
    "        data_2.append([arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.36 GiB for an array with shape (27000, 64, 64, 13) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\Xiaoyi\\new\\musa-650\\MUSA650_Spring2022_HW4(1).ipynb Cell 38'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Xiaoyi/new/musa-650/MUSA650_Spring2022_HW4%281%29.ipynb#ch0000038?line=0'>1</a>\u001b[0m X_2\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49marray( X_2)\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Xiaoyi/new/musa-650/MUSA650_Spring2022_HW4%281%29.ipynb#ch0000038?line=1'>2</a>\u001b[0m X_2\u001b[39m.\u001b[39mshape\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Xiaoyi/new/musa-650/MUSA650_Spring2022_HW4%281%29.ipynb#ch0000038?line=2'>3</a>\u001b[0m X_value_2\u001b[39m=\u001b[39mX_2[:,:,:,:\u001b[39m4\u001b[39m]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.36 GiB for an array with shape (27000, 64, 64, 13) and data type float32"
     ]
    }
   ],
   "source": [
    "X_2=np.array( X_2).astype('float32')\n",
    "X_2.shape\n",
    "X_value_2=X_2[:,:,:,:4]\n",
    "X_value_2/=255\n",
    "Y_value_2=np.array(Y_2)\n",
    "\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(X_value_2, Y_value_2, stratify = Y_value, train_size = 0.5, random_state=42)\n",
    "y_train_2 = to_categorical(y_train_2, num_class)\n",
    "y_test_2 = to_categorical(y_test_2, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 64, 64, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_value_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 62, 62, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                92170     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,778\n",
      "Trainable params: 148,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 4)))\n",
    "model_6.add(MaxPooling2D((2, 2)))\n",
    "model_6.add(Dropout(0.25))\n",
    "model_6.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_6.add(MaxPooling2D((2, 2)))\n",
    "model_6.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_6.add(Flatten())\n",
    "model_6.add(Dense(num_class, activation='softmax'))\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "211/211 [==============================] - 59s 273ms/step - loss: 1.7025 - accuracy: 0.3830 - val_loss: 1.3741 - val_accuracy: 0.4957\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - 59s 278ms/step - loss: 1.2455 - accuracy: 0.5614 - val_loss: 0.9978 - val_accuracy: 0.6413\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - 67s 316ms/step - loss: 1.0517 - accuracy: 0.6334 - val_loss: 1.5797 - val_accuracy: 0.4689\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - 57s 267ms/step - loss: 0.9282 - accuracy: 0.6730 - val_loss: 0.8766 - val_accuracy: 0.7003\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - 58s 273ms/step - loss: 0.8429 - accuracy: 0.7022 - val_loss: 0.9003 - val_accuracy: 0.6786\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - 62s 294ms/step - loss: 0.7632 - accuracy: 0.7341 - val_loss: 0.8292 - val_accuracy: 0.6991\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - 60s 284ms/step - loss: 0.7218 - accuracy: 0.7556 - val_loss: 0.7354 - val_accuracy: 0.7519\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - 61s 288ms/step - loss: 0.6561 - accuracy: 0.7701 - val_loss: 0.9698 - val_accuracy: 0.7096\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - 60s 286ms/step - loss: 0.6216 - accuracy: 0.7846 - val_loss: 0.9797 - val_accuracy: 0.6722\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - 62s 292ms/step - loss: 0.5943 - accuracy: 0.8075 - val_loss: 0.8569 - val_accuracy: 0.7263\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - 61s 290ms/step - loss: 0.5203 - accuracy: 0.8246 - val_loss: 1.0959 - val_accuracy: 0.6490\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - 60s 284ms/step - loss: 0.4939 - accuracy: 0.8381 - val_loss: 2.7604 - val_accuracy: 0.4468\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - 59s 278ms/step - loss: 0.4688 - accuracy: 0.8498 - val_loss: 0.9406 - val_accuracy: 0.7071\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - 60s 286ms/step - loss: 0.4588 - accuracy: 0.8550 - val_loss: 1.1312 - val_accuracy: 0.7376\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.4543 - accuracy: 0.8588 - val_loss: 0.8881 - val_accuracy: 0.7733\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - 62s 296ms/step - loss: 0.3727 - accuracy: 0.8786 - val_loss: 1.0708 - val_accuracy: 0.7501\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - 60s 287ms/step - loss: 0.3710 - accuracy: 0.8845 - val_loss: 0.9454 - val_accuracy: 0.7650\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - 59s 280ms/step - loss: 0.3429 - accuracy: 0.8980 - val_loss: 1.0748 - val_accuracy: 0.7635\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.3537 - accuracy: 0.8958 - val_loss: 2.0705 - val_accuracy: 0.6218\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.3019 - accuracy: 0.9041 - val_loss: 1.8378 - val_accuracy: 0.6576\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - 59s 281ms/step - loss: 0.2696 - accuracy: 0.9137 - val_loss: 1.1445 - val_accuracy: 0.7694\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.3031 - accuracy: 0.9179 - val_loss: 1.5522 - val_accuracy: 0.7212\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - 59s 281ms/step - loss: 0.2716 - accuracy: 0.9174 - val_loss: 1.1318 - val_accuracy: 0.7955\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.2787 - accuracy: 0.9216 - val_loss: 2.5337 - val_accuracy: 0.5613\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - 59s 280ms/step - loss: 0.2617 - accuracy: 0.9260 - val_loss: 1.2608 - val_accuracy: 0.7876\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - 60s 283ms/step - loss: 0.2347 - accuracy: 0.9305 - val_loss: 1.6780 - val_accuracy: 0.7396\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.2186 - accuracy: 0.9373 - val_loss: 1.3689 - val_accuracy: 0.7810\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - 59s 280ms/step - loss: 0.2387 - accuracy: 0.9387 - val_loss: 1.4824 - val_accuracy: 0.7659\n",
      "Epoch 29/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.2116 - accuracy: 0.9397 - val_loss: 1.5205 - val_accuracy: 0.7664\n",
      "Epoch 30/50\n",
      "211/211 [==============================] - 59s 278ms/step - loss: 0.1918 - accuracy: 0.9470 - val_loss: 1.6800 - val_accuracy: 0.7537\n",
      "Epoch 31/50\n",
      "211/211 [==============================] - 61s 288ms/step - loss: 0.2240 - accuracy: 0.9434 - val_loss: 1.5912 - val_accuracy: 0.7602\n",
      "Epoch 32/50\n",
      "211/211 [==============================] - 61s 288ms/step - loss: 0.2039 - accuracy: 0.9490 - val_loss: 1.8421 - val_accuracy: 0.7659\n",
      "Epoch 33/50\n",
      "211/211 [==============================] - 60s 283ms/step - loss: 0.2214 - accuracy: 0.9453 - val_loss: 1.8268 - val_accuracy: 0.7608\n",
      "Epoch 34/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.1852 - accuracy: 0.9504 - val_loss: 2.1984 - val_accuracy: 0.7493\n",
      "Epoch 35/50\n",
      "211/211 [==============================] - 59s 281ms/step - loss: 0.2123 - accuracy: 0.9454 - val_loss: 4.2336 - val_accuracy: 0.5925\n",
      "Epoch 36/50\n",
      "211/211 [==============================] - 59s 281ms/step - loss: 0.2089 - accuracy: 0.9534 - val_loss: 1.9802 - val_accuracy: 0.7823\n",
      "Epoch 37/50\n",
      "211/211 [==============================] - 59s 282ms/step - loss: 0.1790 - accuracy: 0.9551 - val_loss: 1.8658 - val_accuracy: 0.7853\n",
      "Epoch 38/50\n",
      "211/211 [==============================] - 59s 280ms/step - loss: 0.1865 - accuracy: 0.9507 - val_loss: 2.9479 - val_accuracy: 0.6861\n",
      "Epoch 39/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.1938 - accuracy: 0.9528 - val_loss: 2.3127 - val_accuracy: 0.7399\n",
      "Epoch 40/50\n",
      "211/211 [==============================] - 59s 278ms/step - loss: 0.1753 - accuracy: 0.9566 - val_loss: 2.1198 - val_accuracy: 0.7590\n",
      "Epoch 41/50\n",
      "211/211 [==============================] - 59s 281ms/step - loss: 0.1485 - accuracy: 0.9609 - val_loss: 2.1317 - val_accuracy: 0.7419\n",
      "Epoch 42/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.2044 - accuracy: 0.9566 - val_loss: 2.4272 - val_accuracy: 0.7391\n",
      "Epoch 43/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.1853 - accuracy: 0.9608 - val_loss: 2.1595 - val_accuracy: 0.7553\n",
      "Epoch 44/50\n",
      "211/211 [==============================] - 58s 277ms/step - loss: 0.1578 - accuracy: 0.9607 - val_loss: 2.3809 - val_accuracy: 0.7627\n",
      "Epoch 45/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.1555 - accuracy: 0.9638 - val_loss: 2.2884 - val_accuracy: 0.7777\n",
      "Epoch 46/50\n",
      "211/211 [==============================] - 60s 286ms/step - loss: 0.1606 - accuracy: 0.9620 - val_loss: 2.2325 - val_accuracy: 0.7826\n",
      "Epoch 47/50\n",
      "211/211 [==============================] - 59s 280ms/step - loss: 0.1502 - accuracy: 0.9630 - val_loss: 2.2501 - val_accuracy: 0.7596\n",
      "Epoch 48/50\n",
      "211/211 [==============================] - 59s 279ms/step - loss: 0.1414 - accuracy: 0.9664 - val_loss: 3.0320 - val_accuracy: 0.7504\n",
      "Epoch 49/50\n",
      "211/211 [==============================] - 59s 277ms/step - loss: 0.1686 - accuracy: 0.9638 - val_loss: 2.8262 - val_accuracy: 0.7324\n",
      "Epoch 50/50\n",
      "211/211 [==============================] - 58s 277ms/step - loss: 0.1636 - accuracy: 0.9657 - val_loss: 2.4950 - val_accuracy: 0.7881\n",
      "Test loss: 2.49503231048584\n",
      "Test accuracy: 0.7880740761756897\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model_6.fit(x_train_2, y_train_2,\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_2, y_test_2))\n",
    "\n",
    "score = model_6.evaluate(x_test_2, y_test_2, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
